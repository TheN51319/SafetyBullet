cd safepo/single_agent
python ppo_lag.py --task SafetyPointGoal1-v0 --seed 0
python ppo.py --task SafetyPointGoal1-v0 --seed 0
python trpo.py --task SafetyPointGoal1-v0 --seed 0
python ppo.py --task SafetyPointGoal1-v0 --seed 0
python cpo.py --task SafetyPointGoal1-v0 --seed 0 --device "cuda" --num-envs 10  --total-steps 50000000 --experiment cpo_exp
#提供保存路径
python ppo_lag.py   --task SafetyPointGoal1-v0   --experiment ppo_lag_exp


cd safepo/
python evaluate.py --benchmark-dir runs\ppo_lag_exp --eval-episodes 10
python evaluate.py --benchmark-dir runs\single_agent_exp --eval-episodes 10

cd safepo/
python plot.py --logdir ./runs/single_agent_exp


cd safepo/single_agent
python benchmark.py --tasks SafetyAntVelocity-v1 SafetyHalfCheetahVelocity-v1 --algo ppo_lag trpo_lag --workers 2